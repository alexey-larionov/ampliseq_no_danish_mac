---
title: "Ampliseq: check duplicates"
author: "Alexey Larionov"
date: "04 Mar 2021"
output:
  html_document:
    toc: true
    number_sections: true
    toc_float: true
editor_options:
  chunk_output_type: console
---

# Summary  

Check concordance rates for common variants in each-to-each-case basis  
The purpose is to find the intentional duplicates introduced for QC purposes  

Detected 11 pairs of intended QC duplicates (identical to wecare-nfe analysis):  

40_S189_L007 - 41_S328_L008  
76_S299_L008 - 77_S370_L008  
234_S381_L008 - 235_S535_L008  
244_S175_L007 - 245_S59_L007  
280_S173_L007 - 281_S185_L007    **both should be keept as explained by US collaborators**  
347_S36_L007 - 348_S17_L007  
398_S161_L007 - 399_S255_L007  
436_S178_L007 - 437_S177_L007  
517_S450_L008 - 518_S384_L008  
527_S233_L007 - 528_S275_L008  
539_S288_L008 - 540_S461_L008  

and 2 pairs of additional duplicates (with distinct phenotypes):  

270_S70_L007 - 351_S71_L007      **are located near each other on the plate**  
386_S273_L008 - 391_S376_L008  

One pair of intended duplicates was not detected because  
a sample from this pair failed sequencing (108):  
108_S482_L008 - 109_S484_L008  

Input data: 3,758 vars x 535 samples (265UBC + 270CBC)  
No output data  

# Start section

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

```{r echo=F}
options(width = 999)
```

```{r}

# Time stamp
Sys.time()

# Clenan-up
rm(list=ls())
graphics.off()

# Memory
gc()

# Options
options(stringsAsFactors = F,
        warnPartialMatchArgs = T, 
        warnPartialMatchAttr = T, 
        warnPartialMatchDollar = T)

# Files and folders
base_folder="/Users/alexey/Documents/wecare/final_analysis_2021/reanalysis_wo_danish_2021/ampliseq/s01_ampliseq_wecare_only"
data_folder <- file.path(base_folder,"data","s10_filter_samples")
#dir.create(data_folder)
scripts_folder <- file.path(base_folder,"scripts","s10_filter_samples")
setwd(scripts_folder)

```

# Read data

```{r}

# Load data
load(file.path(base_folder,"data","s09_add_phenotypes","s03_add_phenotypes.RData"))

# Update folders
base_folder="/Users/alexey/Documents/wecare/final_analysis_2021/reanalysis_wo_danish_2021/ampliseq/s01_ampliseq_wecare_only"
data_folder <- file.path(base_folder,"data","s10_filter_samples")
scripts_folder <- file.path(base_folder,"scripts","s10_filter_samples")

```

# Check data

```{r}

ls()

dim(genotypes.mx)
dim(phenotypes.df)
dim(variants.df)

sum(colnames(genotypes.mx) != rownames(phenotypes.df))
sum(rownames(genotypes.mx) != rownames(variants.df))

```

# Calculate concordance matrix  

Use common variants only  

The chunk uses slow looping, but it takes < 1min and doesnt need to be optimised because of the small data size  

```{r}

# Select common variants
common_vars <- variants.df$init_AF >= 0.05 & variants.df$init_AF <= 0.95
sum(common_vars)
gt_com.mx <- genotypes.mx[common_vars,]
dim(gt_com.mx)

# Initialise concordance matrix
cnc.mx <- matrix(NA, ncol=ncol(gt_com.mx), nrow=ncol(gt_com.mx))
colnames(cnc.mx) <- colnames(gt_com.mx)
rownames(cnc.mx) <- colnames(gt_com.mx)
cnc.mx[1:5,1:5]

# Initialise counts matrix
cnt.mx <- matrix(NA, ncol=ncol(gt_com.mx), nrow=ncol(gt_com.mx))
colnames(cnt.mx) <- colnames(gt_com.mx)
rownames(cnt.mx) <- colnames(gt_com.mx)
cnt.mx[1:5,1:5]

# Calculate concordances
for(sample_1 in colnames(gt_com.mx)){
  for(sample_2 in colnames(gt_com.mx)){
    
    # Get vectors of variants for both samples
    smp1 <- gt_com.mx[,sample_1]
    smp2 <- gt_com.mx[,sample_2]
    
    # Calculate concordance
    total <- sum(!is.na(smp1) & !is.na(smp2))
    concordant <- sum(smp1==smp2, na.rm=T)
    concordance_rate <- concordant / total
    
    # Write result
    if(sample_1 == sample_2){
      NA  -> cnt.mx[sample_1,sample_2]
      NA  -> cnc.mx[sample_1,sample_2]
    }else{
      total -> cnt.mx[sample_1,sample_2]
      concordance_rate -> cnc.mx[sample_1,sample_2]
    }
  }
}

# Check results
cnt.mx[1:5,1:5]
cnc.mx[1:5,1:5]

# Clean-up
rm(common_vars, gt_com.mx, sample_1, sample_2, smp1, smp2,
   total, concordant, concordance_rate)

```

# Explore concordance matrix

```{r}

# No missed values (except self-concordance/count)
dim(cnt.mx)
sum(is.na(cnt.mx))
sum(is.na(cnc.mx))

# Histograms

hist(cnt.mx)
quantile(cnt.mx, na.rm=T)
mean(cnt.mx, na.rm=T)

hist(cnc.mx, ylim=c(0,140000), lab=T)
hist(cnc.mx[cnc.mx > 0.9], lab=T, ylim=c(0,30))
sum(cnc.mx > 0.9, na.rm=T)
sum(cnc.mx == 1, na.rm=T)

# Make list of most similar samples (concordance > 0.9)
conc_cases.mx <- matrix(nrow=0, ncol=4)
c("sample_1","sample_2","count","concordance") -> colnames(conc_cases.mx)
for(sample_1 in rownames(cnc.mx)){
  for(sample_2 in colnames(cnc.mx)){
    if(sample_1!=sample_2 & cnc.mx[sample_1,sample_2] > 0.9 ){
      conc_cases.mx <- rbind(conc_cases.mx, c(sample_1,sample_2,
                                              cnt.mx[sample_1,sample_2],
                                              cnc.mx[sample_1,sample_2]))
    }
  }
}

# Check result
conc_cases.mx

# Heatmaps
heatmap(cnc.mx, Rowv=NA, Colv=NA, scale='none', 
        col = cm.colors(256), labRow=NA, labCol = NA,
        main="Cases concordance (common variants)")

heatmap(cnc.mx, scale='none', 
        col = cm.colors(256), labRow=NA, labCol = NA,
        main="Cases concordance (common variants, clustered)")

# Clean-up
rm(sample_1, sample_2)

```

# Check phenotypes annotations in concordant cases  

## Expected duplicates  

Phenotype records for expected duplicates are identical,  
except for one case, which is intentionally used twice in different capacities  
(once as case and once as control)  

```{r}

dim(phenotypes.df)
colnames(phenotypes.df)

x <- phenotypes.df["40_S189_L007",] != phenotypes.df["41_S328_L008",]
sum(x[5:24]) # exclude long_ids illumina_id illumina_lane Sample_num fields

x <- phenotypes.df["76_S299_L008",] != phenotypes.df["77_S370_L008",]
sum(x[5:24]) # exclude long_ids illumina_id illumina_lane Sample_num fields

x <- phenotypes.df["234_S381_L008",] != phenotypes.df["235_S535_L008",]
sum(x[5:24]) # exclude long_ids illumina_id illumina_lane Sample_num fields

x <- phenotypes.df["244_S175_L007",] != phenotypes.df["245_S59_L007",]
sum(x[5:24]) # exclude long_ids illumina_id illumina_lane Sample_num fields

x <- phenotypes.df["280_S173_L007",] != phenotypes.df["281_S185_L007",]
sum(x[5:24]) # exclude long_ids illumina_id illumina_lane Sample_num fields
phenotypes.df[c("280_S173_L007","281_S185_L007"),x] 
# cc and rstime differ because used in different capacity for different pairs
# **both samples should be keept in analysis**  

x <- phenotypes.df["347_S36_L007",] != phenotypes.df["348_S17_L007",]
sum(x[5:24]) # exclude long_ids illumina_id illumina_lane Sample_num fields
 
x <- phenotypes.df["398_S161_L007",] != phenotypes.df["399_S255_L007",]
sum(x[5:24]) # exclude long_ids illumina_id illumina_lane Sample_num fields
 
x <- phenotypes.df["436_S178_L007",] != phenotypes.df["437_S177_L007",]
sum(x[5:24]) # exclude long_ids illumina_id illumina_lane Sample_num fields

x <- phenotypes.df["517_S450_L008",] != phenotypes.df["518_S384_L008",]
sum(x[5:24]) # exclude long_ids illumina_id illumina_lane Sample_num fields

x <- phenotypes.df["527_S233_L007",] != phenotypes.df["528_S275_L008",]
sum(x[5:24]) # exclude long_ids illumina_id illumina_lane Sample_num fields

x <- phenotypes.df["539_S288_L008",] != phenotypes.df["540_S461_L008",]
sum(x[5:24]) # exclude long_ids illumina_id illumina_lane Sample_num fields

```

## Unexpected duplicates

Cases in these pairs have very different ages and phenotypes; so it could not be the same sample  

```{r}

x <- phenotypes.df["270_S70_L007",] != phenotypes.df["351_S71_L007",]
sum(x[5:21]) # exclude long_ids illumina_id illumina_lane Sample_num fields
phenotypes.df[c("270_S70_L007","351_S71_L007"),x] 

x <- phenotypes.df["386_S273_L008",] != phenotypes.df["391_S376_L008",]
sum(x[5:21]) # exclude long_ids illumina_id illumina_lane Sample_num fields
phenotypes.df[c("386_S273_L008","391_S376_L008"),x] 

rm(x)

```

# Final section

```{r}

ls()
sessionInfo()
Sys.time()
gc()

```
