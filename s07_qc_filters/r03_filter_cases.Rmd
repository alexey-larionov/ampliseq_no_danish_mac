---
title: "Filter cases and variants ampliseq"
author: "Alexey Larionov"
date: "27 Feb 2021"
output:
  html_document:
    toc: true
    number_sections: true
    toc_float: true
editor_options:
  chunk_output_type: console
---

# Summary 

- Explore mean dp, call rate and Ts/Tv per case  
- Exclude 6 cases with mean_dp<20 **and** call rate <50%:  
    + 108_S482_L008  
    + 152_S511_L008  
    + 306_S410_L008  
    + 346_S276_L008  
    + 384_S486_L008  
    + 498_S507_L008  
- The minimal Ts/Tv ratio is 1.98.  However, many samples had TS/TV >4; and some even >5.  No samples were excluded because of Ts/Tv ratio  
- Exclude 4 sites that became non-polymorphic after the cases removal  
- Check that min variants call rate is still > 0.85 after the cases removal  

Input data: 3,769 vars x 541 cases  
Output data: 3,765 vars x 535 cases  

# Start section

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

```{r echo=F}
options(width = 999)
```

```{r}

# Time stamp
Sys.time()

# Clenan-up
rm(list=ls())
graphics.off()

# Memory
gc()

# Options
options(stringsAsFactors = F,
        warnPartialMatchArgs = T, 
        warnPartialMatchAttr = T, 
        warnPartialMatchDollar = T)

# Files and folders
base_folder="/Users/alexey/Documents/wecare/final_analysis_2021/reanalysis_wo_danish_2021/ampliseq/s01_ampliseq_wecare_only"
data_folder <- file.path(base_folder,"data","s07_qc_filters")
scripts_folder <- file.path(base_folder,"scripts","s07_qc_filters")
setwd(scripts_folder)

# Libraries
library(stringr) # for str_split (in Ti/Tv check)

# Functions
source(file.path(scripts_folder, "f01_TsTv_ratio.R"))

# Cut-offs for cases
min.mean.dp <- 20
min.call.rate <- 0.5

```

# Load data

```{r}

load(file.path(data_folder, "r02_filter_genotypes.RData"))

# Update folders
base_folder="/Users/alexey/Documents/wecare/final_analysis_2021/reanalysis_wo_danish_2021/ampliseq/s01_ampliseq_wecare_only"
data_folder <- file.path(base_folder,"data","s07_qc_filters")
scripts_folder <- file.path(base_folder,"scripts","s07_qc_filters")

```

## Check data

```{r}

# List objects
ls()

# Check sizes
dim(gt.mx)
dim(gt_chr.mx)
dim(dp.mx)
dim(fixed.df)

# Check consistence of row- and col- names
sum(rownames(gt.mx) != rownames(gt_chr.mx))
sum(rownames(gt.mx) != rownames(dp.mx))

sum(colnames(gt.mx) != colnames(gt_chr.mx))
sum(colnames(gt.mx) != colnames(dp.mx))

sum(rownames(gt.mx) != rownames(fixed.df))

```

# Explore data before filters

## dp per sample

```{r}

# Calculate mean depth
mean_dp <- apply(dp.mx, 2, mean, na.rm=T)

# Plot mean depth
plot(mean_dp, main="Mean depth", xlab="Samples", xaxt='n')
abline(h=min.mean.dp, lty=2, col="red")

# Samples with lowest call rates
sort(mean_dp[mean_dp < 20])
low_samples <- names(mean_dp[mean_dp < 20])
low_samples

x <- which(colnames(dp.mx) %in% low_samples)
y <- mean_dp[mean_dp < 20]
low_labs <- substr(low_samples,0,3)
#low_labs[7] <- low_samples[7] # Why?
text(x, y, labels=low_labs, pos=3, cex=0.75)

# Samples with highest call rates
sort(mean_dp[mean_dp > 190])
high_samples <- names(mean_dp[mean_dp > 190])

x <- which(colnames(dp.mx) %in% high_samples)
y <- mean_dp[mean_dp > 190 ]
high_labs <- substr(high_samples,0,3)
high_labs[4:5] <- substr(high_samples[4:5],0,2)
text(x, y, labels=high_labs, pos=1, cex=0.75)

# Clean-up 
rm(dp.mx, mean_dp, low_labs, low_samples, high_samples, high_labs, x, y, min.mean.dp)

```

## call_rates per sample

```{r}

# Function to get call rate
call_rate.udf <- function(x){sum(!is.na(x))/length(x)}

# Calculate mean depth
call_rates <- apply(gt.mx, 2, call_rate.udf)

# Plot mean depth
plot(call_rates, main="Call rates", xlab="Samples", xaxt='n')
abline(h=min.call.rate, lty=2, col="red")

# Samples with lowest call rates
sort(call_rates[call_rates < 0.6])
low_samples <- names(call_rates[call_rates < 0.6])

x <- which(colnames(gt.mx) %in% low_samples)
y <- call_rates[call_rates < 0.6]
low_labs <- substr(low_samples,0,3)
# low_labs[7] <- low_samples[7] Why ?
text(x, y, labels=low_labs, pos=3, cex=0.75)

# Dont exclude sample 510
low_samples
low_samples <- low_samples[1:6]
low_samples

# Clean-up (keep low_samples for later use in filtering)
rm(min.call.rate, call_rates, low_labs, x, y)

```

## TsTv per sample

Needs stringr and TsTv_ratio udf 

```{r}

TsTv.mx <- matrix(ncol=4,nrow=0)
colnames(TsTv.mx) <- c("case","TsTv","Ts","Tv")

for(sample in colnames(gt_chr.mx)){

  #sample <- "147_S493_L008" # A standard sample
  #sample <- "108_S482_L008" # All genotypes are NA: 
  #   will be excluded later for loq call rate
  
  # Initialise result
  z <- c(NA,NA,NA)
  
  # Get vector of genotypes
  g <- gt_chr.mx[,sample]
  
  # If there are at least 100 genotypes
  if(sum(!is.na(g)) > 100){
    
    # Parse genotypes
    x <- str_split(g[!is.na(g)], "/")
    y <- t(matrix(unlist(x),nrow=2))
    
    # Calculate TsTv
    Ref <- y[,1]
    Alt <- y[,2]
    z <- TsTv_ratio(Ref,Alt)
    
  }

  # Write result
  TsTv.mx <- rbind(TsTv.mx,c(sample,z))

}

# Check result
dim(TsTv.mx)
TsTv.mx[1:10,]

# Convert to data frame
TsTv.df <- as.data.frame(TsTv.mx)
TsTv.df$TsTv <- as.numeric(TsTv.mx[,2])
TsTv.df$Ts <- as.numeric(TsTv.mx[,3])
TsTv.df$Tv <- as.numeric(TsTv.mx[,4])
str(TsTv.df)

# Check cases with NA ratio
sum(is.na(TsTv.df$TsTv))

# Make TsTv plot
plot(TsTv.df$TsTv, main="TsTv ratios per sample", 
     xlab="samples", xaxt='n', ylab="Ts/Tv")

abline(h=2, col="red", lty=2)

# High TsTv samples
high_score <- TsTv.df$TsTv>4.6 & !is.na(TsTv.df$TsTv)
sum(high_score)
high_score_samples <- TsTv.df$case[ high_score ]

x <- which(high_score)
y <- TsTv.df[high_score,"TsTv"]
my_labs <- substr(high_score_samples,0,3)

text(x, y, labels=my_labs, cex=0.8, pos=c(1,3,3,1,4))

sum(TsTv.df$TsTv>4.6, na.rm=T)

# Low TsTv samples
low_score <- TsTv.df$TsTv<2 & !is.na(TsTv.df$TsTv)
sum(low_score)
low_score_samples <- TsTv.df$case[ low_score ]

x <- which(low_score)
y <- TsTv.df[low_score,"TsTv"]
my_labs <- substr(low_score_samples,0,3)

text(x, y, labels=my_labs, cex=0.8, pos=4)

# Examples of normal TsTv samples
TsTv.df[200:205, ]

# Highest TsTv samples
TsTv.df[high_score | low_score, ]

# Clean-up
rm(sample, g, x, y, z, Ref, Alt, TsTv_ratio, TsTv.mx, TsTv.df,
   high_score_samples, high_score, low_score_samples, low_score, gt_chr.mx, my_labs)

```

# Remove failed samples 

```{r}

low_samples
retained_samples <- ! colnames(gt.mx) %in% low_samples

dim(gt.mx)
gt.mx <- gt.mx[,retained_samples]
dim(gt.mx)

rm(low_samples, retained_samples)

```

# Remove non-polymorphic sites created by the samples filtering

Remove 4 variants: 3,769 -> 3,765  

```{r}

# Function to detect uniform numeric vector
uniformity_check.udf <- function(x){
  if (all(is.na(x))){"All_NA"}
  else if (min(x,na.rm=T)==max(x,na.rm=T)){"Uniform"}
  else {"Non-Uniform"}}

# Make the filter
uniformity_check <- apply(gt.mx,1,uniformity_check.udf)
summary(as.factor(uniformity_check))
non_uniform_sites <- uniformity_check == "Non-Uniform"

# Remove variants with uniform genotypes accross all samples
gt.mx <- gt.mx[non_uniform_sites,]
fixed.df <- fixed.df[non_uniform_sites,]

dim(gt.mx)
dim(fixed.df)

# Clean-up
rm(uniformity_check.udf, uniformity_check, non_uniform_sites)

```

# Check variants call rate

No variant callrate has dropped below 0.85, so no additional variant removal is needed    

```{r}

var_call_rates <- apply(gt.mx, 1, call_rate.udf)
length(var_call_rates)
min(var_call_rates)

# Clean-up
rm(call_rate.udf, var_call_rates)

```

# Data summary

```{r}

ls()

# Check sizes
dim(gt.mx)
dim(fixed.df)

# Check consistence of rownames and colnames
sum(rownames(gt.mx) != rownames(fixed.df))

```

# Save data

```{r}

save.image(file.path(data_folder, "r03_filter_cases.RData"))

```

# Final section

```{r}

ls()
sessionInfo()
Sys.time()
gc()

```
